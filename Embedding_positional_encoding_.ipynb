{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6KOIphRGcO8ZdBDIHqgNC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twishi03/Graph/blob/main/Embedding_positional_encoding_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Embeddings capture the meaning of words\n",
        "#Positional encoding adds position info to embeddings\n",
        "#Combining them gives context-aware representations"
      ],
      "metadata": {
        "id": "rReCdYm3ng47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCMPMa0LkOq7",
        "outputId": "6ea63f90-b87e-42a8-a50e-7c2419f50a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "yy1KxjqGkYwJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the Vocabulary and Embedding Layer\n",
        "#Next, we will define the vocabulary size and the embedding dimension, and create the embedding layer:"
      ],
      "metadata": {
        "id": "vgMcymHIlmCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the vocabulary size and embedding dimension\n",
        "vocab_size = 10  # For simplicity, we will use a small vocabulary\n",
        "embedding_dim = 4  # Size of each embedding vector\n",
        "\n",
        "# Create the embedding layer\n",
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)"
      ],
      "metadata": {
        "id": "HnsruQ1YkYtF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vocabulary Size: We set a small vocabulary size (10) for this example. In practice, this would be the total number of unique tokens in your dataset.\n",
        "#Embedding Dimension: We choose an embedding dimension of 4, meaning each token will be represented by a 4-dimensional vector.\n",
        "#Embedding Layer: We create an instance of nn.Embedding, which initializes the embedding weights randomly."
      ],
      "metadata": {
        "id": "wzC270Nql5Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization and Mapping to IDs\n",
        "# we will tokenize the input sentence and map the tokens to unique IDs. For simplicity, we will manually define the mapping:"
      ],
      "metadata": {
        "id": "itzRr9I4mR07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input sentence\n",
        "sentence = \"The cat sat on the mat.\"\n",
        "\n",
        "# Manual tokenization and mapping to IDs\n",
        "tokens = [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "print(\"Token to ID mapping:\", token_to_id)\n",
        "\n",
        "# Convert tokens to IDs\n",
        "token_ids = [token_to_id[\"The\"], token_to_id[\"cat\"], token_to_id[\"sat\"],\n",
        "             token_to_id[\"on\"], token_to_id[\"the\"], token_to_id[\"mat\"]]\n",
        "print(\"Token IDs:\", token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP0gF3BRkYqC",
        "outputId": "0257443f-158f-491c-c19c-19cf0b78d5da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token to ID mapping: {'The': 0, 'cat': 1, 'sat': 2, 'on': 3, 'the': 4, 'mat': 5}\n",
            "Token IDs: [0, 1, 2, 3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Token IDs to Embeddings\n",
        "# Now, we will convert the token IDs into their corresponding embeddings using the embedding layer:"
      ],
      "metadata": {
        "id": "XI_ARdQBmlO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert token IDs to a tensor\n",
        "input_tensor = torch.tensor(token_ids)\n",
        "\n",
        "# Get the embeddings for the input tokens\n",
        "embeddings = embedding_layer(input_tensor)\n",
        "print(\"Embeddings:\\n\", embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llqpcBI_kj_y",
        "outputId": "488829b8-165c-4d59-8dda-f822fe230369"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings:\n",
            " tensor([[-0.1895, -0.7090, -0.4066, -0.1553],\n",
            "        [-0.5835, -0.4718,  0.3449, -0.0829],\n",
            "        [-1.9861,  0.6218,  0.3677,  0.6417],\n",
            "        [ 0.3010, -0.0173,  1.2684, -0.6471],\n",
            "        [-0.9190,  1.3044,  0.4334, -0.4524],\n",
            "        [ 0.7899,  0.0160, -1.3633, -1.1432]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Words with Their Corresponding Embeddings\n",
        "# After retrieving the embeddings, you can use the token_to_id mapping to print each token alongside its embedding vector. Hereâ€™s the additional code to achieve that:"
      ],
      "metadata": {
        "id": "CkFanyabmsua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the tokens with their corresponding embeddings\n",
        "print(\"Tokens with their Embeddings:\")\n",
        "for token, token_id in token_to_id.items():\n",
        "    print(f\"{token}: {embeddings[token_id].detach().numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u-c2iXikmCb",
        "outputId": "a4e65818-586d-4550-a39d-146afa536ed0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens with their Embeddings:\n",
            "The: [-0.18949166 -0.7090116  -0.4065933  -0.15532453]\n",
            "cat: [-0.5835363  -0.47175115  0.34488687 -0.08287223]\n",
            "sat: [-1.9861022   0.6218238   0.36767727  0.6417273 ]\n",
            "on: [ 0.3010073  -0.01734046  1.268361   -0.64714956]\n",
            "the: [-0.9189837   1.3043665   0.43335357 -0.45244074]\n",
            "mat: [ 0.78989875  0.01604908 -1.3633478  -1.1431677 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Positional Encoding Function\n",
        "# Next, we will create a function to generate positional encodings based on the formulas we discussed earlier."
      ],
      "metadata": {
        "id": "rgMHtxlkm6Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(seq_len, d_model):\n",
        "    # Create a tensor for positional encodings\n",
        "    pos_enc = torch.zeros(seq_len, d_model)\n",
        "\n",
        "    # Calculate positional encodings\n",
        "    positions = torch.arange(seq_len, dtype=torch.float).unsqueeze(1)  # Shape (seq_len, 1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))  # Shape (d_model/2,)\n",
        "\n",
        "    pos_enc[:, 0::2] = torch.sin(positions * div_term)  # Apply sine to even indices\n",
        "    pos_enc[:, 1::2] = torch.cos(positions * div_term)  # Apply cosine to odd indices\n",
        "\n",
        "    return pos_enc"
      ],
      "metadata": {
        "id": "bTDWulDsklui"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Positional Encodings\n",
        "# Now, we will generate the positional encodings for our input sentence."
      ],
      "metadata": {
        "id": "G4RUm39DnGi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sequence length (number of tokens) and embedding dimension\n",
        "seq_len = len(tokens)  # Number of tokens in the input sentence\n",
        "d_model = embedding_dim  # Use the same embedding dimension as before\n",
        "\n",
        "# Generate positional encodings\n",
        "positional_encodings = positional_encoding(seq_len, d_model)\n",
        "print(\"Positional Encodings:\\n\", positional_encodings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7AQZNnckxMN",
        "outputId": "3a59cac2-338e-4c40-f604-6bae82574871"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional Encodings:\n",
            " tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
            "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
            "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
            "        [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
            "        [-0.7568, -0.6536,  0.0400,  0.9992],\n",
            "        [-0.9589,  0.2837,  0.0500,  0.9988]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Positional Encodings to Input Embeddings\n",
        "# Finally, we will add the positional encodings to the input embeddings we created earlier."
      ],
      "metadata": {
        "id": "a4-BFbtJnL48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_embeddings = embeddings + positional_encodings\n",
        "print(\"Encoded Embeddings (with Positional Encoding):\\n\", encoded_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwTxmjb4kxI8",
        "outputId": "ce7616e0-323a-48a4-ce8a-5641feba5083"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Embeddings (with Positional Encoding):\n",
            " tensor([[-0.1895,  0.2910, -0.4066,  0.8447],\n",
            "        [ 0.2579,  0.0686,  0.3549,  0.9171],\n",
            "        [-1.0768,  0.2057,  0.3877,  1.6415],\n",
            "        [ 0.4421, -1.0073,  1.2984,  0.3524],\n",
            "        [-1.6758,  0.6507,  0.4733,  0.5468],\n",
            "        [-0.1690,  0.2997, -1.3134, -0.1444]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ]
}